{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Introduction to model validation**\n",
    "___\n",
    "- What is model validation?\n",
    "    - Model validation consists of:\n",
    "        - ensuring your model performs as expected on new data\n",
    "        - testing model performance on holdout datasets\n",
    "        - selecting the best model, parameters, and accuracy metrics\n",
    "        - achieving the best accuracy for the data given\n",
    "- scikit-learn modeling review\n",
    "    - Basic modeling steps\n",
    "        - model = RandomForestRegressor(n_estimators=500, random_state=1111_\n",
    "        - model.fit(X=X_train, y=y_train)\n",
    "        - predictions = model.predict(X_test)\n",
    "        - print(\"{0:.2f}\".format(mae(y_true=y_test, y_pred=predictions)))\n",
    "            - e.g., \"10.84\"\n",
    "            - Mean Absolute Error\n",
    "                - (sum |y true - y pred|) / n\n",
    "- this course uses 538's ultimate Holloween Candy Power ranking dataset\n",
    "- Seen vs. unseen data\n",
    "    - training data = seen data\n",
    "    - testing data = unseen data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Seen vs. unseen data\n",
    "\n",
    "#Model's tend to have higher accuracy on observations they have seen\n",
    "#before. In the candy dataset, predicting the popularity of Skittles\n",
    "#will likely have higher accuracy than predicting the popularity of\n",
    "#Andes Mints; Skittles is in the dataset, and Andes Mints is not.\n",
    "\n",
    "#You've built a model based on 50 candies using the dataset X_train\n",
    "#and need to report how accurate the model is at predicting the\n",
    "#popularity of the 50 candies the model was built on, and the 35\n",
    "#candies (X_test) it has never seen. You will use the mean absolute\n",
    "#error, mae(), as the accuracy metric.\n",
    "\n",
    "# The model is fit using X_train and y_train\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Create vectors of predictions\n",
    "#train_predictions = model.predict(X_train)\n",
    "#test_predictions = model.predict(X_test)\n",
    "\n",
    "# Train/Test Errors\n",
    "#train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
    "#test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
    "\n",
    "# Print the accuracy for seen and unseen data\n",
    "#print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
    "#print(\"Model error on unseen data: {0:.2f}.\".format(test_error))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    Model error on seen data: 3.28.\n",
    "#    Model error on unseen data: 11.07.\n",
    "#################################################\n",
    "#When models perform differently on training and testing data, you\n",
    "#should look to model validation to ensure you have the best performing\n",
    "#model. In the next lesson, you will start building models to validate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Regression models**\n",
    "___\n",
    "- Random forests in scikit-learn\n",
    "    - decision trees\n",
    "    - mean prediction of decision trees = final value for observation\n",
    "    - parameters\n",
    "        - n_estimators: the number of trees in the forest\n",
    "        - max_depth: tha maximum depth of the trees\n",
    "        - random_state: random seed for reproducibility\n",
    "    - feature importance\n",
    "        - .feature_importances_\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Set parameters and fit a model\n",
    "\n",
    "#Predictive tasks fall into one of two categories: regression or\n",
    "#classification. In the candy dataset, the outcome is a continuous\n",
    "#variable describing how often the candy was chosen over another\n",
    "#candy in a series of 1-on-1 match-ups. To predict this value (the\n",
    "#win-percentage), you will use a regression model.\n",
    "\n",
    "#In this exercise, you will specify a few parameters using a random\n",
    "#forest regression model rfr.\n",
    "\n",
    "# Set the number of trees\n",
    "#rfr.n_estimators = 100\n",
    "\n",
    "# Add a maximum depth\n",
    "#rfr.max_depth = 6\n",
    "\n",
    "# Set the random state\n",
    "#rfr.random_state = 1111\n",
    "\n",
    "# Fit the model\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "#################################################\n",
    "#You have updated parameters after the model was initialized. This\n",
    "#approach is helpful when you need to update parameters. Before\n",
    "#making predictions, let's see which candy characteristics were most\n",
    "#important to the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Feature importances\n",
    "\n",
    "#Although some candy attributes, such as chocolate, may be extremely\n",
    "#popular, it doesn't mean they will be important to model prediction.\n",
    "#After a random forest model has been fit, you can review the model's\n",
    "#attribute, .feature_importances_, to see which variables had the\n",
    "#biggest impact. You can check how important each variable was in the\n",
    "#model by looping over the feature importance array using enumerate().\n",
    "\n",
    "#If you are unfamiliar with Python's enumerate() function, it can loop\n",
    "#over a list while also creating an automatic counter.\n",
    "\n",
    "# Fit the model using X and y\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print how important each column is to the model\n",
    "#for i, item in enumerate(rfr.feature_importances_):\n",
    "    # Use i and item to print out the feature importance of each column\n",
    "#    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    chocolate: 0.44\n",
    "#    fruity: 0.03\n",
    "#    caramel: 0.02\n",
    "#    peanutyalmondy: 0.05\n",
    "#    nougat: 0.01\n",
    "#    crispedricewafer: 0.03\n",
    "#    hard: 0.01\n",
    "#    bar: 0.02\n",
    "#    pluribus: 0.02\n",
    "#    sugarpercent: 0.17\n",
    "#    pricepercent: 0.19\n",
    "#################################################\n",
    "#No surprise here - chocolate is the most important variable.\n",
    "#.feature_importances_ is a great way to see which variables were\n",
    "#important to your random forest model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Classification models**\n",
    "___\n",
    "- Categorical Responses\n",
    "- Tic-Tac-Toe dataset\n",
    "- .predict()\n",
    "    - sparse array\n",
    "- .predict_proba()\n",
    "- .get_params()\n",
    "- .score(X_test, y_test)\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Classification predictions\n",
    "\n",
    "#In model validation, it is often important to know more about the\n",
    "#predictions than just the final classification. When predicting\n",
    "#who will win a game, most people are also interested in how likely\n",
    "#it is a team will win.\n",
    "\n",
    "#Probability\tPrediction\tMeaning\n",
    "#0 < .50\t        0\t    Team Loses\n",
    "#.50 +\t            1\t    Team Wins\n",
    "\n",
    "#In this exercise, you look at the methods, .predict() and\n",
    "#.predict_proba() using the tic_tac_toe dataset. The first method\n",
    "#will give a prediction of whether Player One will win the game, and\n",
    "#the second method will provide the probability of Player One winning.\n",
    "#Use rfc as the random forest classification model.\n",
    "\n",
    "# Fit the rfc model.\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create arrays of predictions\n",
    "#classification_predictions = rfc.predict(X_test)\n",
    "#probability_predictions = rfc.predict_proba(X_test)\n",
    "\n",
    "# Print out count of binary predictions\n",
    "#print(pd.Series(classification_predictions).value_counts())\n",
    "\n",
    "# Print the first value from probability_predictions\n",
    "#print('The first predicted probabilities are: {}'.format(probability_predictions[0]))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    1    563\n",
    "#    0    204\n",
    "#    dtype: int64\n",
    "#    The first predicted probabilities are: [0.26524423 0.73475577]\n",
    "#################################################\n",
    "#ou can see there were 563 observations where Player One was\n",
    "#predicted to win the Tic-Tac-Toe game. Also, note that the\n",
    "#predicted_probabilities array contains lists with only two values\n",
    "#because you only have two possible responses (win or lose). Remember\n",
    "#these two methods, as you will use them a lot throughout this course."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Reusing model parameters\n",
    "#Replicating model performance is vital in model validation. Replication\n",
    "#is also important when sharing models with co-workers, reusing models\n",
    "#on new data or asking questions on a website such as Stack Overflow.\n",
    "#You might use such a site to ask other coders about model errors,\n",
    "#output, or performance. The best way to do this is to replicate your\n",
    "#work by reusing model parameters.\n",
    "\n",
    "#In this exercise, you use various methods to recall which parameters\n",
    "#were used in a model.\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Print the classification model\n",
    "#print(rfc)\n",
    "\n",
    "# Print the classification model's random state parameter\n",
    "#print('The random state is: {}'.format(rfc.random_state))\n",
    "\n",
    "# Print all parameters\n",
    "#print('Printing the parameters dictionary: {}'.format(rfc.get_params()))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
    "#                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                min_samples_leaf=1, min_samples_split=2,\n",
    "#                min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
    "#                oob_score=False, random_state=1111, verbose=0,\n",
    "#                warm_start=False)\n",
    "#    The random state is: 1111\n",
    "#    Printing the parameters dictionary: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n",
    "#################################################\n",
    "#Recalling which parameters were used will be helpful going forward.\n",
    "#Model validation and performance rely heavily on which parameters\n",
    "#were used, and there is no way to replicate a model without keeping\n",
    "#track of the parameters used!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Random forest classifier\n",
    "\n",
    "#This exercise reviews the four modeling steps discussed throughout\n",
    "#this chapter using a random forest classification model. You will:\n",
    "\n",
    "#Create a random forest classification model.\n",
    "#Fit the model using the tic_tac_toe dataset.\n",
    "#Make predictions on whether Player One will win (1) or lose (0) the current game.\n",
    "#Finally, you will evaluate the overall accuracy of the model.\n",
    "\n",
    "#Let's get started!\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "#rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Fit rfc using X_train and y_train\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions on X_test\n",
    "#predictions = rfc.predict(X_test)\n",
    "#print(predictions[0:5])\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    [1 1 1 1 1]\n",
    "#################################################\n",
    "\n",
    "# Print model accuracy using score() and the testing data\n",
    "#print(rfc.score(X_test, y_test))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.817470664928292\n",
    "#################################################\n",
    "#Notice the first five predictions were all 1, indicating that\n",
    "#Player One is predicted to win all five of those games. You also\n",
    "#see the model accuracy was only 82%.\n",
    "\n",
    "#Let's move on to Chapter 2 and increase our model validation toolbox\n",
    "#by learning about splitting datasets, standard accuracy metrics, and\n",
    "#the bias-variance tradeoff."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating train, test, and validation datasets**\n",
    "___\n",
    "- Ratio Examples\n",
    "    - 80:20\n",
    "    - 90:10\n",
    "        - used when we have little data\n",
    "    - 70:30\n",
    "        - used when model is computationally expensive\n",
    "- test_size\n",
    "- train_size\n",
    "- random_state\n",
    "- validation samples are used when testing different parameters\n",
    "    - it is a holdout sample taken from the training sample\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create one holdout set\n",
    "#Your boss has asked you to create a simple random forest model on the\n",
    "#tic_tac_toe dataset. She doesn't want you to spend much time selecting\n",
    "#parameters; rather she wants to know how well the model will perform\n",
    "#on future data. For future Tic-Tac-Toe games, it would be nice to know\n",
    "#if your model can predict which player will win.\n",
    "\n",
    "#The dataset tic_tac_toe has been loaded for your use.\n",
    "\n",
    "#Note that in Python, =\\ indicates the code was too long for one line\n",
    "#and has been split across two lines.\n",
    "\n",
    "# Create dummy variables using pandas\n",
    "#X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9])\n",
    "#y = tic_tac_toe.iloc[:, 9]\n",
    "\n",
    "# Create training and testing datasets. Use 10% for the test set\n",
    "#X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.10, random_state=1111)\n",
    "\n",
    "#################################################\n",
    "#Remember, without the holdout set, you cannot truly validate a model.\n",
    "#Let's move on to creating two holdout sets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create two holdout sets\n",
    "\n",
    "#You recently created a simple random forest model to predict Tic-Tac-Toe\n",
    "#game wins for your boss, and at her request, you did not do any\n",
    "#parameter tuning. Unfortunately, the overall model accuracy was too\n",
    "#low for her standards. This time around, she has asked you to focus\n",
    "#on model performance.\n",
    "\n",
    "#Before you start testing different models and parameter sets, you\n",
    "#will need to split the data into training, validation, and testing\n",
    "#datasets. Remember that after splitting the data into training and\n",
    "#testing datasets, the validation dataset is created by splitting the\n",
    "#training dataset.\n",
    "\n",
    "#The datasets X and y have been loaded for your use.\n",
    "\n",
    "# Create temporary training and final testing datasets\n",
    "#X_temp, X_test, y_temp, y_test  =\\\n",
    "#    train_test_split(X, y, test_size=0.20, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "#X_train, X_val, y_train, y_val  =\\\n",
    "#    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)\n",
    "\n",
    "#################################################\n",
    "#You now have training, validation, and testing datasets, but do you\n",
    "#know when you need both validation and testing datasets?\n",
    "#When testing parameters, tuning hyper-parameters, or anytime you are\n",
    "#frequently evaluating model performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Accuracy metrics: regression models**\n",
    "___\n",
    "- Mean Absolute Error (MAE)\n",
    "    - most intuitive\n",
    "- Mean Squared Error (MSE)\n",
    "    - same as MAE except the difference term is squared\n",
    "    - allows outlier errors to contribute more to the overall error\n",
    "    - most widely used\n",
    "- MAE vs MSE\n",
    "    - accuracy metrics are always application specific\n",
    "    - MAE and MSE error terms are in different units and should not be compared\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Mean absolute error\n",
    "\n",
    "#Communicating modeling results can be difficult. However, most clients\n",
    "#understand that on average, a predictive model was off by some number.\n",
    "#This makes explaining the mean absolute error easy. For example, when\n",
    "#predicting the number of wins for a basketball team, if you predict 42,\n",
    "#and they end up with 40, you can easily explain that the error was\n",
    "#two wins.\n",
    "\n",
    "#In this exercise, you are interviewing for a new position and are\n",
    "#provided with two arrays. y_test, the true number of wins for all\n",
    "#30 NBA teams in 2017 and predictions, which contains a prediction\n",
    "#for each team. To test your understanding, you are asked to both\n",
    "#manually calculate the MAE and use sklearn.\n",
    "\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Manually calculate the MAE\n",
    "#n = len(predictions)\n",
    "#mae_one = sum(abs(y_test - predictions)) / n\n",
    "#print('With a manual calculation, the error is {}'.format(mae_one))\n",
    "\n",
    "# Use scikit-learn to calculate the MAE\n",
    "#mae_two = mean_absolute_error(y_test, predictions)\n",
    "#print('Using scikit-lean, the error is {}'.format(mae_two))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    With a manual calculation, the error is 5.9\n",
    "#    Using scikit-lean, the error is 5.9\n",
    "#################################################\n",
    "#These predictions were about six wins off on average. This isn't\n",
    "#too bad considering NBA teams play 82 games a year. Let's see how\n",
    "#these errors would look if you used the mean squared error instead."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Mean squared error\n",
    "\n",
    "#Let's focus on the 2017 NBA predictions again. Every year, there are\n",
    "#at least a couple of NBA teams that win way more games than expected.\n",
    "#If you use the MAE, this accuracy metric does not reflect the bad\n",
    "#predictions as much as if you use the MSE. Squaring the large errors\n",
    "#from bad predictions will make the accuracy look worse.\n",
    "\n",
    "#In this example, NBA executives want to better predict team wins.\n",
    "#You will use the mean squared error to calculate the prediction\n",
    "#error. The actual wins are loaded as y_test and the predictions as\n",
    "#predictions.\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#n = len(predictions)\n",
    "# Finish the manual calculation of the MSE\n",
    "#mse_one = sum((y_test - predictions)**2) / n\n",
    "#print('With a manual calculation, the error is {}'.format(mse_one))\n",
    "\n",
    "# Use the scikit-learn function to calculate MSE\n",
    "#mse_two = mean_squared_error(y_test, predictions)\n",
    "#print('Using scikit-learn, the error is {}'.format(mse_two))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    With a manual calculation, the error is 49.1\n",
    "#    Using scikit-learn, the error is 49.1\n",
    "#################################################\n",
    "# If you run any additional models, you will try to beat an MSE of 49.1,\n",
    "#which is the average squared error of using your model. Although the\n",
    "#MSE is not as interpretable as the MAE, it will help us select a\n",
    "#model that has fewer 'large' errors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Performance on data subsets\n",
    "\n",
    "#In professional basketball, there are two conferences, the East and\n",
    "#the West. Coaches and fans often only care about how teams in their\n",
    "#own conference will do this year.\n",
    "\n",
    "#You have been working on an NBA prediction model and would like to\n",
    "#determine if the predictions were better for the East or West\n",
    "#conference. You added a third array to your data called labels,\n",
    "#which contains an \"E\" for the East teams, and a \"W\" for the West.\n",
    "#y_test and predictions have again been loaded for your use.\n",
    "\n",
    "# Find the East conference teams\n",
    "#east_teams = labels == \"E\"\n",
    "\n",
    "# Create arrays for the true and predicted values\n",
    "#true_east = y_test[east_teams]\n",
    "#preds_east = predictions[east_teams]\n",
    "\n",
    "# Print the accuracy metrics\n",
    "#print('The MAE for East teams is {}'.format(\n",
    "#    mae(true_east, preds_east)))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The MAE for East teams is 6.733333333333333\n",
    "#################################################\n",
    "\n",
    "# Print the West accuracy\n",
    "#print('The MAE for West conference is {}'.format(west_error))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    <script.py> output:\n",
    "#    The MAE for West conference is 5.01\n",
    "#################################################\n",
    "#It looks like the Western conference predictions were about two\n",
    "#games better on average. Over the past few seasons, the Western teams\n",
    "#have generally won the same number of games as the experts have\n",
    "#predicted. Teams in the East are just not as predictable as those\n",
    "#in the West."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Classification metrics**\n",
    "___\n",
    "- Examples\n",
    "    - **precision**\n",
    "    - **recall**/sensitivity\n",
    "    - **accuracy**\n",
    "    - specificity\n",
    "    - f-1 score and its variations\n",
    "    - etc...\n",
    "\n",
    "- Confusion Matrix\n",
    "    - confusion_matrix\n",
    "![_images/17.1.PNG](_images/17.1.PNG)\n",
    "\n",
    "- Accuracy\n",
    "    - overall ability of a model to predict correct classification\n",
    "![_images/17.2.PNG](_images/17.2.PNG)\n",
    "\n",
    "- Precision\n",
    "    - when we don't want to overpredict positive values\n",
    "    - e.g., the number of invited interviewees who accept a position\n",
    "![_images/17.3.PNG](_images/17.3.PNG)\n",
    "\n",
    "- Recall\n",
    "    - when we can't afford to miss any positive values\n",
    "    - e.g., even if a patient has a small chance of having cancer\n",
    "![_images/17.4.PNG](_images/17.4.PNG)\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Confusion matrices\n",
    "\n",
    "#Confusion matrices are a great way to start exploring your model's\n",
    "#accuracy. They provide the values needed to calculate a wide range\n",
    "#of metrics, including sensitivity, specificity, and the F1-score.\n",
    "\n",
    "#You have built a classification model to predict if a person has a\n",
    "#broken arm based on an X-ray image. On the testing set, you have the\n",
    "#following confusion matrix:\n",
    "\n",
    "#\t         Prediction: 0\tPrediction: 1\n",
    "#Actual: 0\t 324 (TN)\t    15 (FP)\n",
    "#Actual: 1\t 123 (FN)\t    491 (TP)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "#accuracy = (491 + 324) / (953)\n",
    "#print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
    "\n",
    "# Calculate and print the precision\n",
    "#precision = (491) / (491 + 15)\n",
    "#print(\"The precision is {0: 0.2f}\".format(precision))\n",
    "\n",
    "# Calculate and print the recall\n",
    "#recall = (491) / (491 + 123)\n",
    "#print(\"The recall is {0: 0.2f}\".format(recall))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The overall accuracy is  0.86\n",
    "#    The precision is  0.97\n",
    "#    The recall is  0.80\n",
    "#################################################\n",
    "#In this case, a true positive is a picture of an actual broken arm\n",
    "#that was also predicted to be broken. Doctors are okay with a few\n",
    "#additional false positives (predicted broken, not actually broken),\n",
    "#as long as you don't miss anyone who needs immediate medical attention."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Confusion matrices, again\n",
    "\n",
    "#Creating a confusion matrix in Python is simple. The biggest challenge\n",
    "#will be making sure you understand the orientation of the matrix. This\n",
    "#exercise makes sure you understand the sklearn implementation of\n",
    "#confusion matrices. Here, you have created a random forest model\n",
    "#using the tic_tac_toe dataset rfc to predict outcomes of 0 (loss) or\n",
    "#1 (a win) for Player One.\n",
    "\n",
    "#Note: If you read about confusion matrices on another website or for\n",
    "#another programming language, the values might be reversed.\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create predictions\n",
    "#test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create and print the confusion matrix\n",
    "#cm = confusion_matrix(y_test, test_predictions)\n",
    "#print(cm)\n",
    "\n",
    "# Print the true positives (actual 1s that were predicted 1s)\n",
    "#print(\"The number of true positives is: {}\".format(cm[1, 1]))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    [[177 123]\n",
    "#     [ 92 471]]\n",
    "#    The number of true positives is: 471\n",
    "#################################################\n",
    "#Row 1, column 1 represents the number of actual 1s that were predicted\n",
    "#1s (the true positives). Always make sure you understand the orientation\n",
    "#of the confusion matrix before you start using it!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Precision vs. recall\n",
    "\n",
    "#The accuracy metrics you use to evaluate your model should always be\n",
    "#based on the specific application. For this example, let's assume\n",
    "#you are a really sore loser when it comes to playing Tic-Tac-Toe,\n",
    "#but only when you are certain that you are going to win.\n",
    "\n",
    "#Choose the most appropriate accuracy metric, either precision or\n",
    "#recall, to complete this example. But remember, if you think you\n",
    "#are going to win, you better win!\n",
    "\n",
    "#Use rfc, which is a random forest classification model built on the\n",
    "#tic_tac_toe dataset.\n",
    "\n",
    "#from sklearn.metrics import precision_score\n",
    "\n",
    "#test_predictions = rfc.predict(X_test)\n",
    "\n",
    "# Create precision or recall score based on the metric you imported\n",
    "#score = precision_score(y_test, test_predictions)\n",
    "\n",
    "# Print the final result\n",
    "#print(\"The precision value is {0:.2f}\".format(score))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The precision value is 0.79\n",
    "#################################################\n",
    "#Precision is the correct metric here. Sore-losers can't stand losing\n",
    "#when they are certain they will win! For that reason, our model needs\n",
    "#to be as precise as possible. With a precision of only 79%, you may\n",
    "#need to try some other modeling techniques to improve this score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The bias-variance tradeoff**\n",
    "___\n",
    "- Variance\n",
    "    - following the training data too closely\n",
    "    - fails to generalize to test data\n",
    "    - low training error but high testing error\n",
    "    - occurs when models are overfit and have high complexity\n",
    "![_images/17.5.PNG](_images/17.5.PNG)\n",
    "\n",
    "- Bias\n",
    "    - failing to find the relationship between the data and the response\n",
    "    - high training and testing error\n",
    "    - occurs when models are underfit\n",
    "    - e.g., not enough trees, trees not deep enough\n",
    "![_images/17.6.PNG](_images/17.6.PNG)\n",
    "\n",
    "- Optimal performance\n",
    "![_images/17.7.PNG](_images/17.7.PNG)\n",
    "\n",
    "- Parameters causing over/underfitting\n",
    "    - max_depth\n",
    "    - max_features\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Error due to under/over-fitting\n",
    "\n",
    "#The candy dataset is prime for overfitting. With only 85 observations,\n",
    "#if you use 20% for the testing dataset, you are losing a lot of vital\n",
    "#data that could be used for modeling. Imagine the scenario where most\n",
    "#of the chocolate candies ended up in the training data and very few\n",
    "#in the holdout sample. Our model might only see that chocolate is a\n",
    "#vital factor, but fail to find that other attributes are also\n",
    "#important. In this exercise, you'll explore how using too many features\n",
    "#(columns) in a random forest model can lead to overfitting.\n",
    "\n",
    "#A feature represents which columns of the data are used in a\n",
    "#decision tree. The parameter max_features limits the number of\n",
    "#features available.\n",
    "\n",
    "# Update the rfr model\n",
    "#rfr = RandomForestRegressor(n_estimators=25,\n",
    "#                            random_state=1111,\n",
    "#                            max_features=2)\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies\n",
    "#print('The training error is {0:.2f}'.format(\n",
    "#  mae(y_train, rfr.predict(X_train))))\n",
    "#print('The testing error is {0:.2f}'.format(\n",
    "#  mae(y_test, rfr.predict(X_test))))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The training error is 3.88\n",
    "#    The testing error is 9.15\n",
    "#################################################\n",
    "\n",
    "# Update the rfr model\n",
    "#rfr = RandomForestRegressor(n_estimators=25,\n",
    "#                            random_state=1111,\n",
    "#                            max_features=11)\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies\n",
    "#print('The training error is {0:.2f}'.format(\n",
    "#  mae(y_train, rfr.predict(X_train))))\n",
    "#print('The testing error is {0:.2f}'.format(\n",
    "#  mae(y_test, rfr.predict(X_test))))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The training error is 3.57\n",
    "#    The testing error is 10.05\n",
    "#################################################\n",
    "\n",
    "# Update the rfr model\n",
    "#rfr = RandomForestRegressor(n_estimators=25,\n",
    "#                            random_state=1111,\n",
    "#                            max_features=4)\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print the training and testing accuracies\n",
    "#print('The training error is {0:.2f}'.format(\n",
    "#  mae(y_train, rfr.predict(X_train))))\n",
    "#print('The testing error is {0:.2f}'.format(\n",
    "#  mae(y_test, rfr.predict(X_test))))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The training error is 3.60\n",
    "#    The testing error is 8.79\n",
    "#################################################\n",
    "#The chart below shows the performance at various max feature values.\n",
    "#Sometimes, setting parameter values can make a huge difference in\n",
    "#model performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/17.8.png](_images/17.8.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Am I underfitting?\n",
    "\n",
    "#You are creating a random forest model to predict if you will win a\n",
    "#future game of Tic-Tac-Toe. Using the tic_tac_toe dataset, you have\n",
    "#created training and testing datasets, X_train, X_test, y_train, and\n",
    "#y_test.\n",
    "\n",
    "#You have decided to create a bunch of random forest models with\n",
    "#varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more\n",
    "#trees you use, the longer your random forest model will take to run.\n",
    "#However, if you don't use enough trees, you risk underfitting. You\n",
    "#have created a for loop to test your model at the different number\n",
    "#of trees.\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#test_scores, train_scores = [], []\n",
    "#for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "#    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "#    rfc.fit(X_train, y_train)\n",
    "    # Create predictions for the X_train and X_test datasets.\n",
    "#    train_predictions = rfc.predict(X_train)\n",
    "#    test_predictions = rfc.predict(X_test)\n",
    "    # Append the accuracy score for the test and train predictions.\n",
    "#    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "#    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
    "# Print the train and test scores.\n",
    "#print(\"The training scores were: {}\".format(train_scores))\n",
    "#print(\"The testing scores were: {}\".format(test_scores))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\n",
    "#    The testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n",
    "#################################################\n",
    "#Notice that with only one tree, both the train and test scores are\n",
    "#low. As you add more trees, both errors improve. Even at 50 trees,\n",
    "#this still might not be enough. Every time you use more trees, you\n",
    "#achieve higher accuracy. At some point though, more trees increase\n",
    "#training time, but do not decrease testing error."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}