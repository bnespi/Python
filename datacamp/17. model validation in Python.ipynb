{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Introduction to model validation**\n",
    "___\n",
    "- What is model validation?\n",
    "    - Model validation consists of:\n",
    "        - ensuring your model performs as expected on new data\n",
    "        - testing model performance on holdout datasets\n",
    "        - selecting the best model, parameters, and accuracy metrics\n",
    "        - achieving the best accuracy for the data given\n",
    "- scikit-learn modeling review\n",
    "    - Basic modeling steps\n",
    "        - model = RandomForestRegressor(n_estimators=500, random_state=1111_\n",
    "        - model.fit(X=X_train, y=y_train)\n",
    "        - predictions = model.predict(X_test)\n",
    "        - print(\"{0:.2f}\".format(mae(y_true=y_test, y_pred=predictions)))\n",
    "            - e.g., \"10.84\"\n",
    "            - Mean Absolute Error\n",
    "                - (sum |y true - y pred|) / n\n",
    "- this course uses 538's ultimate Holloween Candy Power ranking dataset\n",
    "- Seen vs. unseen data\n",
    "    - training data = seen data\n",
    "    - testing data = unseen data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Seen vs. unseen data\n",
    "\n",
    "#Model's tend to have higher accuracy on observations they have seen\n",
    "#before. In the candy dataset, predicting the popularity of Skittles\n",
    "#will likely have higher accuracy than predicting the popularity of\n",
    "#Andes Mints; Skittles is in the dataset, and Andes Mints is not.\n",
    "\n",
    "#You've built a model based on 50 candies using the dataset X_train\n",
    "#and need to report how accurate the model is at predicting the\n",
    "#popularity of the 50 candies the model was built on, and the 35\n",
    "#candies (X_test) it has never seen. You will use the mean absolute\n",
    "#error, mae(), as the accuracy metric.\n",
    "\n",
    "# The model is fit using X_train and y_train\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Create vectors of predictions\n",
    "#train_predictions = model.predict(X_train)\n",
    "#test_predictions = model.predict(X_test)\n",
    "\n",
    "# Train/Test Errors\n",
    "#train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
    "#test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
    "\n",
    "# Print the accuracy for seen and unseen data\n",
    "#print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
    "#print(\"Model error on unseen data: {0:.2f}.\".format(test_error))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    Model error on seen data: 3.28.\n",
    "#    Model error on unseen data: 11.07.\n",
    "#################################################\n",
    "#When models perform differently on training and testing data, you\n",
    "#should look to model validation to ensure you have the best performing\n",
    "#model. In the next lesson, you will start building models to validate."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Regression models**\n",
    "___\n",
    "- Random forests in scikit-learn\n",
    "    - decision trees\n",
    "    - mean prediction of decision trees = final value for observation\n",
    "    - parameters\n",
    "        - n_estimators: the number of trees in the forest\n",
    "        - max_depth: tha maximum depth of the trees\n",
    "        - random_state: random seed for reproducibility\n",
    "    - feature importance\n",
    "        - .feature_importances_\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Set parameters and fit a model\n",
    "\n",
    "#Predictive tasks fall into one of two categories: regression or\n",
    "#classification. In the candy dataset, the outcome is a continuous\n",
    "#variable describing how often the candy was chosen over another\n",
    "#candy in a series of 1-on-1 match-ups. To predict this value (the\n",
    "#win-percentage), you will use a regression model.\n",
    "\n",
    "#In this exercise, you will specify a few parameters using a random\n",
    "#forest regression model rfr.\n",
    "\n",
    "# Set the number of trees\n",
    "#rfr.n_estimators = 100\n",
    "\n",
    "# Add a maximum depth\n",
    "#rfr.max_depth = 6\n",
    "\n",
    "# Set the random state\n",
    "#rfr.random_state = 1111\n",
    "\n",
    "# Fit the model\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "#################################################\n",
    "#You have updated parameters after the model was initialized. This\n",
    "#approach is helpful when you need to update parameters. Before\n",
    "#making predictions, let's see which candy characteristics were most\n",
    "#important to the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Feature importances\n",
    "\n",
    "#Although some candy attributes, such as chocolate, may be extremely\n",
    "#popular, it doesn't mean they will be important to model prediction.\n",
    "#After a random forest model has been fit, you can review the model's\n",
    "#attribute, .feature_importances_, to see which variables had the\n",
    "#biggest impact. You can check how important each variable was in the\n",
    "#model by looping over the feature importance array using enumerate().\n",
    "\n",
    "#If you are unfamiliar with Python's enumerate() function, it can loop\n",
    "#over a list while also creating an automatic counter.\n",
    "\n",
    "# Fit the model using X and y\n",
    "#rfr.fit(X_train, y_train)\n",
    "\n",
    "# Print how important each column is to the model\n",
    "#for i, item in enumerate(rfr.feature_importances_):\n",
    "    # Use i and item to print out the feature importance of each column\n",
    "#    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    chocolate: 0.44\n",
    "#    fruity: 0.03\n",
    "#    caramel: 0.02\n",
    "#    peanutyalmondy: 0.05\n",
    "#    nougat: 0.01\n",
    "#    crispedricewafer: 0.03\n",
    "#    hard: 0.01\n",
    "#    bar: 0.02\n",
    "#    pluribus: 0.02\n",
    "#    sugarpercent: 0.17\n",
    "#    pricepercent: 0.19\n",
    "#################################################\n",
    "#No surprise here - chocolate is the most important variable.\n",
    "#.feature_importances_ is a great way to see which variables were\n",
    "#important to your random forest model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Classification models**\n",
    "___\n",
    "- Categorical Responses\n",
    "- Tic-Tac-Toe dataset\n",
    "- .predict()\n",
    "    - sparse array\n",
    "- .predict_proba()\n",
    "- .get_params()\n",
    "- .score(X_test, y_test)\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Classification predictions\n",
    "\n",
    "#In model validation, it is often important to know more about the\n",
    "#predictions than just the final classification. When predicting\n",
    "#who will win a game, most people are also interested in how likely\n",
    "#it is a team will win.\n",
    "\n",
    "#Probability\tPrediction\tMeaning\n",
    "#0 < .50\t        0\t    Team Loses\n",
    "#.50 +\t            1\t    Team Wins\n",
    "\n",
    "#In this exercise, you look at the methods, .predict() and\n",
    "#.predict_proba() using the tic_tac_toe dataset. The first method\n",
    "#will give a prediction of whether Player One will win the game, and\n",
    "#the second method will provide the probability of Player One winning.\n",
    "#Use rfc as the random forest classification model.\n",
    "\n",
    "# Fit the rfc model.\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create arrays of predictions\n",
    "#classification_predictions = rfc.predict(X_test)\n",
    "#probability_predictions = rfc.predict_proba(X_test)\n",
    "\n",
    "# Print out count of binary predictions\n",
    "#print(pd.Series(classification_predictions).value_counts())\n",
    "\n",
    "# Print the first value from probability_predictions\n",
    "#print('The first predicted probabilities are: {}'.format(probability_predictions[0]))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    1    563\n",
    "#    0    204\n",
    "#    dtype: int64\n",
    "#    The first predicted probabilities are: [0.26524423 0.73475577]\n",
    "#################################################\n",
    "#ou can see there were 563 observations where Player One was\n",
    "#predicted to win the Tic-Tac-Toe game. Also, note that the\n",
    "#predicted_probabilities array contains lists with only two values\n",
    "#because you only have two possible responses (win or lose). Remember\n",
    "#these two methods, as you will use them a lot throughout this course."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Reusing model parameters\n",
    "#Replicating model performance is vital in model validation. Replication\n",
    "#is also important when sharing models with co-workers, reusing models\n",
    "#on new data or asking questions on a website such as Stack Overflow.\n",
    "#You might use such a site to ask other coders about model errors,\n",
    "#output, or performance. The best way to do this is to replicate your\n",
    "#work by reusing model parameters.\n",
    "\n",
    "#In this exercise, you use various methods to recall which parameters\n",
    "#were used in a model.\n",
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Print the classification model\n",
    "#print(rfc)\n",
    "\n",
    "# Print the classification model's random state parameter\n",
    "#print('The random state is: {}'.format(rfc.random_state))\n",
    "\n",
    "# Print all parameters\n",
    "#print('Printing the parameters dictionary: {}'.format(rfc.get_params()))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
    "#                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                min_samples_leaf=1, min_samples_split=2,\n",
    "#                min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
    "#                oob_score=False, random_state=1111, verbose=0,\n",
    "#                warm_start=False)\n",
    "#    The random state is: 1111\n",
    "#    Printing the parameters dictionary: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n",
    "#################################################\n",
    "#Recalling which parameters were used will be helpful going forward.\n",
    "#Model validation and performance rely heavily on which parameters\n",
    "#were used, and there is no way to replicate a model without keeping\n",
    "#track of the parameters used!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Random forest classifier\n",
    "\n",
    "#This exercise reviews the four modeling steps discussed throughout\n",
    "#this chapter using a random forest classification model. You will:\n",
    "\n",
    "#Create a random forest classification model.\n",
    "#Fit the model using the tic_tac_toe dataset.\n",
    "#Make predictions on whether Player One will win (1) or lose (0) the current game.\n",
    "#Finally, you will evaluate the overall accuracy of the model.\n",
    "\n",
    "#Let's get started!\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "#rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
    "\n",
    "# Fit rfc using X_train and y_train\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions on X_test\n",
    "#predictions = rfc.predict(X_test)\n",
    "#print(predictions[0:5])\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    [1 1 1 1 1]\n",
    "#################################################\n",
    "\n",
    "# Print model accuracy using score() and the testing data\n",
    "#print(rfc.score(X_test, y_test))\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.817470664928292\n",
    "#################################################\n",
    "#Notice the first five predictions were all 1, indicating that\n",
    "#Player One is predicted to win all five of those games. You also\n",
    "#see the model accuracy was only 82%.\n",
    "\n",
    "#Let's move on to Chapter 2 and increase our model validation toolbox\n",
    "#by learning about splitting datasets, standard accuracy metrics, and\n",
    "#the bias-variance tradeoff."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating train, test, and validation datasets**\n",
    "___\n",
    "\n",
    "___\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}