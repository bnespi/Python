{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Timeseries kinds and applications**\n",
    "___\n",
    "- data that changes over time\n",
    "    - e.g., atmospheric changes, demographic information, financial data, voice wave forms\n",
    "    - datapoints and timestamps for each data point\n",
    "- in machine learning, changes over time shows useful patterns in machine learning\n",
    "- a machine learning pipeline\n",
    "    - feature extraction\n",
    "    - model fitting\n",
    "    - prediction and validation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting a time series (I)\n",
    "\n",
    "#In this exercise, you'll practice plotting the values of two time\n",
    "#series without the time component.\n",
    "\n",
    "#Two DataFrames, data and data2 are available in your workspace.\n",
    "\n",
    "#Unless otherwise noted, assume that all required packages are loaded\n",
    "#with their common aliases throughout this course.\n",
    "\n",
    "#Note: This course assumes some familiarity with time series data,\n",
    "#as well as how to use them in data analytics pipelines. For an\n",
    "#introduction to time series, we recommend the Introduction to Time\n",
    "#Series Analysis in Python and Visualizing Time Series Data with Python\n",
    "#courses.\n",
    "\n",
    "# Print the first 5 rows of data\n",
    "#print(data.head())\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    symbol  data_values\n",
    "#    0        214.009998\n",
    "#    1        214.379993\n",
    "#    2        210.969995\n",
    "#    3        210.580000\n",
    "#    4        211.980005\n",
    "#################################################\n",
    "\n",
    "# Print the first 5 rows of data2\n",
    "#print(data2.head())\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#       data_values\n",
    "#    0    -0.006928\n",
    "#    1    -0.007929\n",
    "#    2    -0.008900\n",
    "#    3    -0.009815\n",
    "#    4    -0.010653\n",
    "#################################################\n",
    "\n",
    "# Plot the time series in each dataset\n",
    "#fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "#data.iloc[:1000].plot(y=\"data_values\", ax=axs[0])\n",
    "#data2.iloc[:1000].plot(y=\"data_values\", ax=axs[1])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.1.svg](_images/15.1.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting a time series (II)\n",
    "\n",
    "#You'll now plot both the datasets again, but with the included time\n",
    "#stamps for each (stored in the column called \"time\"). Let's see if\n",
    "#this gives you some more context for understanding each time series\n",
    "#data.\n",
    "\n",
    "# Plot the time series in each dataset\n",
    "#fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "#data.iloc[:1000].plot(x=\"time\", y=\"data_values\", ax=axs[0])\n",
    "#data2.iloc[:1000].plot(x=\"time\", y=\"data_values\", ax=axs[1])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.2.svg](_images/15.2.svg)\n",
    "As you can now see, each time series has a very different sampling\n",
    "frequency (the amount of time between samples). The first is daily\n",
    "stock market data, and the second is an audio waveform."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Machine learning basics**\n",
    "___\n",
    "- always begin by looking at your data\n",
    "- scikit-learn data needs to be 2 dimensional\n",
    "    - (samples, features)\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Fitting a simple model: classification\n",
    "\n",
    "#In this exercise, you'll use the iris dataset (representing petal\n",
    "#characteristics of a number of flowers) to practice using the\n",
    "#scikit-learn API to fit a classification model. You can see a sample\n",
    "#plot of the data below.\n",
    "\n",
    "#Note: This course assumes some familiarity with Machine Learning\n",
    "#and scikit-learn. For an introduction to scikit-learn, we recommend\n",
    "#the Supervised Learning with Scikit-Learn and Preprocessing for\n",
    "#Machine Learning in Python courses."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.3.svg](_images/15.3.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print the first 5 rows for inspection\n",
    "#print(data.head())\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#        sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
    "#    50                7.0               3.2                4.7               1.4\n",
    "#    51                6.4               3.2                4.5               1.5\n",
    "#    52                6.9               3.1                4.9               1.5\n",
    "#    53                5.5               2.3                4.0               1.3\n",
    "#    54                6.5               2.8                4.6               1.5\n",
    "#\n",
    "#        target\n",
    "#    50       1\n",
    "#    51       1\n",
    "#    52       1\n",
    "#    53       1\n",
    "#    54       1\n",
    "#################################################\n",
    "\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "# Construct data for the model\n",
    "#X = data[['petal length (cm)', 'petal width (cm)']]\n",
    "#y = data[['target']]\n",
    "\n",
    "# Fit the model\n",
    "#model = LinearSVC()\n",
    "#model.fit(X, y)\n",
    "\n",
    "#################################################\n",
    "#You've successfully fit a classifier to predict flower type!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predicting using a classification model\n",
    "\n",
    "#Now that you have fit your classifier, let's use it to predict the\n",
    "#type of flower (or class) for some newly-collected flowers.\n",
    "\n",
    "#Information about petal width and length for several new flowers is\n",
    "#stored in the variable targets. Using the classifier you fit, you'll\n",
    "#predict the type of each flower.\n",
    "\n",
    "# Create input array\n",
    "#X_predict = targets[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "# Predict with the model\n",
    "#predictions = model.predict(X_predict)\n",
    "#print(predictions)\n",
    "\n",
    "# Visualize predictions and actual values\n",
    "#plt.scatter(X_predict['petal length (cm)'], X_predict['petal width (cm)'],\n",
    "#            c=predictions, cmap=plt.cm.coolwarm)\n",
    "#plt.title(\"Predicted class values\")\n",
    "#plt.show()\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    [2 2 2 1 1 2 2 2 2 1 2 1 1 2 1 1 2 1 2 2]\n",
    "#################################################\n",
    "#Note that the output of your predictions are all integers,\n",
    "#representing that datapoint's predicted class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.4.svg](_images/15.4.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Fitting a simple model: regression\n",
    "\n",
    "#In this exercise, you'll practice fitting a regression model using\n",
    "#data from the Boston housing market. A DataFrame called boston is\n",
    "#available in your workspace. It contains many variables of data\n",
    "#(stored as columns). Can you find a relationship between the\n",
    "#following two variables?\n",
    "\n",
    "#\"AGE\": proportion of owner-occupied units built prior to 1940\n",
    "#\"RM\" : average number of rooms per dwelling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.5.svg](_images/15.5.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from sklearn import linear_model\n",
    "\n",
    "# Prepare input and output DataFrames\n",
    "#X = boston[['AGE']]\n",
    "#y = boston[['RM']]\n",
    "\n",
    "# Fit the model\n",
    "#model = linear_model.LinearRegression()\n",
    "#model.fit(X, y)\n",
    "\n",
    "#################################################\n",
    "# In regression, the output of your model is a continuous array of\n",
    "#numbers, not class identity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predicting using a regression model\n",
    "\n",
    "#Now that you've fit a model with the Boston housing data, lets see\n",
    "#what predictions it generates on some new data. You can investigate\n",
    "#the underlying relationship that the model has found between inputs\n",
    "#and outputs by feeding in a range of numbers as inputs and seeing\n",
    "#what the model predicts for each input.\n",
    "\n",
    "#A 1-D array new_inputs consisting of 100 \"new\" values for \"AGE\"\n",
    "#(proportion of owner-occupied units built prior to 1940) is\n",
    "#available in your workspace along with the model you fit in the\n",
    "#previous exercise.\n",
    "\n",
    "# Generate predictions with the model using those inputs\n",
    "#predictions = model.predict(new_inputs.reshape(-1, 1))\n",
    "\n",
    "# Visualize the inputs and predicted values\n",
    "#plt.scatter(new_inputs, predictions, color='r', s=3)\n",
    "#plt.xlabel('inputs')\n",
    "#plt.ylabel('predictions')\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.6.svg](_images/15.6.svg)\n",
    "Here the red line shows the relationship that your model found. As\n",
    "the proportion of pre-1940s houses gets larger, the average number\n",
    "of rooms gets slightly lower."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Machine learning and time series data**\n",
    "___\n",
    "- using audio data of heart sounds to detect who has a heart condition\n",
    "- using new york stock exchange data to detect patterns in historical records that allow us to predict the value of companies in the future\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Inspecting the classification data\n",
    "\n",
    "#In these final exercises of this chapter, you'll explore the two\n",
    "#datasets you'll use in this course.\n",
    "\n",
    "#The first is a collection of heartbeat sounds. Hearts normally have\n",
    "#a predictable sound pattern as they beat, but some disorders can\n",
    "#cause the heart to beat abnormally. This dataset contains a training\n",
    "#set with labels for each type of heartbeat, and a testing set with no\n",
    "#labels. You'll use the testing set to validate your models.\n",
    "\n",
    "#As you have labeled data, this dataset is ideal for classification.\n",
    "#In fact, it was originally offered as a part of a public Kaggle\n",
    "#competition. https://www.kaggle.com/kinguistics/heartbeat-sounds\n",
    "\n",
    "#import librosa as lr\n",
    "#from glob import glob\n",
    "\n",
    "# List all the wav files in the folder\n",
    "#audio_files = glob(data_dir + '/*.wav')\n",
    "\n",
    "# Read in the first audio file, create the time array\n",
    "#audio, sfreq = lr.load(audio_files[0])\n",
    "#time = np.arange(0, len(audio)) / sfreq\n",
    "\n",
    "# Plot audio over time\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(time, audio)\n",
    "#ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.7.svg](_images/15.7.svg)\n",
    "There are several seconds of heartbeat sounds in here, though note\n",
    "that most of this time is silence. A common procedure in machine\n",
    "learning is to separate the datapoints with lots of stuff happening\n",
    "from the ones that don't."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Inspecting the regression data\n",
    "\n",
    "#The next dataset contains information about company market value\n",
    "#over several years of time. This is one of the most popular kind\n",
    "#of time series data used for regression. If you can model the value\n",
    "#of a company as it changes over time, you can make predictions about\n",
    "#where that company will be in the future. This dataset was also\n",
    "#originally provided as part of a public Kaggle competition.\n",
    "#https://www.kaggle.com/dgawlik/nyse\n",
    "\n",
    "#In this exercise, you'll plot the time series for a number of\n",
    "#companies to get an understanding of how they are (or aren't)\n",
    "#related to one another.\n",
    "\n",
    "# Read in the data\n",
    "#data = pd.read_csv('prices.csv', index_col=0)\n",
    "\n",
    "# Convert the index of the DataFrame to datetime\n",
    "#data.index = pd.to_datetime(data.index)\n",
    "#print(data.head())\n",
    "\n",
    "# Loop through each column, plot its values over time\n",
    "#fig, ax = plt.subplots()\n",
    "#for column in data.columns:\n",
    "#    data[column].plot(ax=ax, label=column)\n",
    "#ax.legend()\n",
    "#plt.show()\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#                      AAPL  FB       NFLX          V        XOM\n",
    "#    time\n",
    "#    2010-01-04  214.009998 NaN  53.479999  88.139999  69.150002\n",
    "#    2010-01-05  214.379993 NaN  51.510001  87.129997  69.419998\n",
    "#    2010-01-06  210.969995 NaN  53.319999  85.959999  70.019997\n",
    "#    2010-01-07  210.580000 NaN  52.400001  86.760002  69.800003\n",
    "#    2010-01-08  211.980005 NaN  53.300002  87.000000  69.519997\n",
    "#################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.8.svg](_images/15.8.svg)\n",
    "Note that each company's value is sometimes correlated with others,\n",
    "and sometimes not. Also note there are a lot of 'jumps' in there -\n",
    "what effect do you think these jumps would have on a predictive model?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Classifying a time series**\n",
    "___\n",
    "- always visualize raw data before fitting models\n",
    "- start with summary statistics\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Many repetitions of sounds\n",
    "\n",
    "#In this exercise, you'll start with perhaps the simplest\n",
    "#classification technique: averaging across dimensions of a dataset\n",
    "#and visually inspecting the result.\n",
    "\n",
    "#You'll use the heartbeat data described in the last chapter. Some\n",
    "#recordings are normal heartbeat activity, while others are abnormal\n",
    "#activity. Let's see if you can spot the difference.\n",
    "\n",
    "#Two DataFrames, normal and abnormal, each with the shape of\n",
    "#(n_times_points, n_audio_files) containing the audio for several\n",
    "#heartbeats are available in your workspace. Also, the sampling\n",
    "#frequency is loaded into a variable called sfreq. A convenience\n",
    "#plotting function show_plot_and_make_titles() is also available in\n",
    "#your workspace.\n",
    "\n",
    "#fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "# Calculate the time array\n",
    "#time = np.arange(normal.shape[0]) / sfreq\n",
    "\n",
    "# Stack the normal/abnormal audio so you can loop and plot\n",
    "#stacked_audio = np.hstack([normal, abnormal]).T\n",
    "\n",
    "# Loop through each audio file / ax object and plot\n",
    "# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\n",
    "#for iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n",
    "#    ax.plot(time, iaudio)\n",
    "#show_plot_and_make_titles()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.9.svg](_images/15.9.svg)\n",
    "As you can see there is a lot of variability in the raw data, let's\n",
    "see if you can average out some of that noise to notice a difference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Invariance in time\n",
    "\n",
    "#While you should always start by visualizing your raw data, this is\n",
    "#often uninformative when it comes to discriminating between two\n",
    "#classes of data points. Data is usually noisy or exhibits complex\n",
    "#patterns that aren't discoverable by the naked eye.\n",
    "\n",
    "#Another common technique to find simple differences between two\n",
    "#sets of data is to average across multiple instances of the same\n",
    "#class. This may remove noise and reveal underlying patterns (or,\n",
    "#it may not).\n",
    "\n",
    "#In this exercise, you'll average across many instances of each\n",
    "#class of heartbeat sound.\n",
    "\n",
    "#The two DataFrames (normal and abnormal) and the time array (time)\n",
    "#from the previous exercise are available in your workspace.\n",
    "\n",
    "# Average across the audio files of each DataFrame\n",
    "#mean_normal = np.mean(normal, axis=1)\n",
    "#mean_abnormal = np.mean(abnormal, axis=1)\n",
    "\n",
    "# Plot each average over time\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "#ax1.plot(time, mean_normal)\n",
    "#ax1.set(title=\"Normal Data\")\n",
    "#ax2.plot(time, mean_abnormal)\n",
    "#ax2.set(title=\"Abnormal Data\")\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.10.svg](_images/15.10.svg)\n",
    "Do you see a noticeable difference between the two? Maybe, but it's\n",
    "quite noisy. Let's see how you can dig into the data a bit further."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Build a classification model\n",
    "\n",
    "#While eye-balling differences is a useful way to gain an intuition\n",
    "#for the data, let's see if you can operationalize things with a\n",
    "#model. In this exercise, you will use each repetition as a\n",
    "#datapoint, and each moment in time as a feature to fit a classifier\n",
    "#that attempts to predict abnormal vs. normal heartbeats using only\n",
    "#the raw data.\n",
    "\n",
    "#We've split the two DataFrames (normal and abnormal) into X_train,\n",
    "#X_test, y_train, and y_test.\n",
    "\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize and fit the model\n",
    "#model = LinearSVC()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions and score them manually\n",
    "#predictions = model.predict(X_test)\n",
    "#print(sum(predictions == y_test.squeeze()) / len(y_test))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.555555555556\n",
    "#################################################\n",
    "#Note that your predictions didn't do so well. That's because the\n",
    "#features you're using as inputs to the model (raw data) aren't very\n",
    "#good at differentiating classes. Next, you'll explore how to calculate\n",
    "#some more complex features that may improve the results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Improving features for classification**\n",
    "___\n",
    "- The auditory envelope\n",
    "    - smooth the data to calculate the auditory envelope\n",
    "    - related to the amount of audio energy present at each moment in time\n",
    "- smoothing over time\n",
    "    - instead of averaging over time, we do a local average\n",
    "    - this is called smoothing your timeseries\n",
    "    - it removes short-term noise, while retaining the general pattern\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Calculating the envelope of sound\n",
    "#One of the ways you can improve the features available to your\n",
    "#model is to remove some of the noise present in the data. In audio\n",
    "#data, a common way to do this is to smooth the data and then rectify\n",
    "#it so that the total amount of sound energy over time is more\n",
    "#distinguishable. You'll do this in the current exercise.\n",
    "\n",
    "#A heartbeat file is available in the variable audio.\n",
    "\n",
    "# Plot the raw data first\n",
    "#audio.plot(figsize=(10, 5))\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.11.svg](_images/15.11.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rectify the audio signal\n",
    "#audio_rectified = audio.apply(np.abs)\n",
    "\n",
    "# Plot the result\n",
    "#audio_rectified.plot(figsize=(10, 5))\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.12.svg](_images/15.12.svg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Smooth by applying a rolling mean\n",
    "#audio_rectified_smooth = audio_rectified.rolling(50).mean()\n",
    "\n",
    "# Plot the result\n",
    "#audio_rectified_smooth.plot(figsize=(10, 5))\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.13.svg](_images/15.13.svg)\n",
    "By calculating the envelope of each sound and smoothing it, you've\n",
    "eliminated much of the noise and have a cleaner signal to tell you\n",
    "when a heartbeat is happening."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Calculating features from the envelope\n",
    "\n",
    "#Now that you've removed some of the noisier fluctuations in the\n",
    "#audio, let's see if this improves your ability to classify.\n",
    "\n",
    "#audio_rectified_smooth from the previous exercise is available in\n",
    "#your workspace.\n",
    "\n",
    "# Calculate stats\n",
    "#means = np.mean(audio_rectified_smooth, axis=0)\n",
    "#stds = np.std(audio_rectified_smooth, axis=0)\n",
    "#maxs = np.max(audio_rectified_smooth, axis=0)\n",
    "\n",
    "# Create the X and y arrays\n",
    "#X = np.column_stack([means, stds, maxs])\n",
    "#y = labels.reshape([-1, 1])\n",
    "\n",
    "# Fit the model and score on testing data\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#percent_score = cross_val_score(model, X, y, cv=5)\n",
    "#print(np.mean(percent_score))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.716666666667\n",
    "#################################################\n",
    "#This model is both simpler (only 3 features) and more understandable\n",
    "#(features are simple summary statistics of the data)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Derivative features: The tempogram\n",
    "\n",
    "#One benefit of cleaning up your data is that it lets you compute\n",
    "#more sophisticated features. For example, the envelope calculation\n",
    "#you performed is a common technique in computing tempo and rhythm\n",
    "#features. In this exercise, you'll use librosa to compute some\n",
    "#tempo and rhythm features for heartbeat data, and fit a model once\n",
    "#more.\n",
    "\n",
    "#Note that librosa functions tend to only operate on numpy arrays\n",
    "#instead of DataFrames, so we'll access our Pandas data as a Numpy\n",
    "#array with the .values attribute.\n",
    "\n",
    "# Calculate the tempo of the sounds\n",
    "#tempos = []\n",
    "#for col, i_audio in audio.items():\n",
    "#    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))\n",
    "\n",
    "# Convert the list to an array so you can manipulate it more easily\n",
    "#tempos = np.array(tempos)\n",
    "\n",
    "# Calculate statistics of each tempo\n",
    "#tempos_mean = tempos.mean(axis=-1)\n",
    "#tempos_std = tempos.std(axis=-1)\n",
    "#tempos_max = tempos.max(axis=-1)\n",
    "\n",
    "# Create the X and y arrays\n",
    "#X = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])\n",
    "#y = labels.reshape([-1, 1])\n",
    "\n",
    "# Fit the model and score on testing data\n",
    "#percent_score = cross_val_score(model, X, y, cv=5)\n",
    "#print(np.mean(percent_score))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.533333333333\n",
    "#################################################\n",
    "#Note that your predictive power may not have gone up (because this\n",
    "#dataset is quite small), but you now have a more rich feature\n",
    "#representation of audio that your model can use!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The spectrogram**\n",
    "___\n",
    "- fourier transform\n",
    "    - timeseries data can be described as a combination of quickly-changing and slowly-changing things\n",
    "    - at each moment in time, we can describe the relative presence of fast- and slow-moving components\n",
    "    - this converts a single timeseries into an array that describes the timeseries as a combination of oscillations\n",
    "- short time (st) fft is squared = spectrogram\n",
    "- spectral feature engineering\n",
    "    - each timeseries has a different spectral pattern\n",
    "    - we can calculate these spectral patterns by analyzing the spectrogram to describe where most of the energy is at each moment in time\n",
    "        - **spectral bandwidth**\n",
    "        - **spectral centroids**\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Spectrograms of heartbeat audio\n",
    "\n",
    "#Spectral engineering is one of the most common techniques in\n",
    "#machine learning for time series data. The first step in this\n",
    "#process is to calculate a spectrogram of sound. This describes what\n",
    "#spectral content (e.g., low and high pitches) are present in the\n",
    "#sound over time. In this exercise, you'll calculate a spectrogram\n",
    "#of a heartbeat audio file.\n",
    "\n",
    "#We've loaded a single heartbeat sound in the variable audio.\n",
    "\n",
    "# Import the functions you'll use for the STFT\n",
    "#from librosa.core import stft\n",
    "\n",
    "# Prepare the STFT\n",
    "#HOP_LENGTH = 2**4\n",
    "#spec = stft(audio, hop_length=HOP_LENGTH, n_fft=2**7)\n",
    "\n",
    "#from librosa.core import amplitude_to_db\n",
    "#from librosa.display import specshow\n",
    "\n",
    "# Convert into decibels\n",
    "#spec_db = amplitude_to_db(spec)\n",
    "\n",
    "# Compare the raw audio to the spectrogram of the audio\n",
    "#fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
    "#axs[0].plot(time, audio)\n",
    "#specshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.14.svg](_images/15.14.svg)\n",
    "Do you notice that the heartbeats come in pairs, as seen by the\n",
    "vertical lines in the spectrogram?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Engineering spectral features\n",
    "\n",
    "#As you can probably tell, there is a lot more information in a\n",
    "#spectrogram compared to a raw audio file. By computing the spectral\n",
    "#features, you have a much better idea of what's going on. As such,\n",
    "#there are all kinds of spectral features that you can compute using\n",
    "#the spectrogram as a base. In this exercise, you'll look at a few\n",
    "#of these features.\n",
    "\n",
    "#The spectogram spec from the previous exercise is available in your\n",
    "#workspace.\n",
    "\n",
    "#import librosa as lr\n",
    "\n",
    "# Calculate the spectral centroid and bandwidth for the spectrogram\n",
    "#bandwidths = lr.feature.spectral_bandwidth(S=spec)[0]\n",
    "#centroids = lr.feature.spectral_centroid(S=spec)[0]\n",
    "\n",
    "#from librosa.core import amplitude_to_db\n",
    "#from librosa.display import specshow\n",
    "\n",
    "# Convert spectrogram to decibels for visualization\n",
    "#spec_db = amplitude_to_db(spec)\n",
    "\n",
    "# Display these features on top of the spectrogram\n",
    "#fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#ax = specshow(spec_db, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\n",
    "#ax.plot(times_spec, centroids)\n",
    "#ax.fill_between(times_spec, centroids - bandwidths / 2, centroids + bandwidths / 2, alpha=.5)\n",
    "#ax.set(ylim=[None, 6000])\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![_images/15.15.svg](_images/15.15.svg)\n",
    "As you can see, the spectral centroid and bandwidth characterize the\n",
    "spectral content in each sound over time. They give us a summary of\n",
    "the spectral content that we can use in a classifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combining many features in a classifier\n",
    "\n",
    "#You've spent this lesson engineering many features from the audio\n",
    "#data - some contain information about how the audio changes in time,\n",
    "#others contain information about the spectral content that is\n",
    "#present.\n",
    "\n",
    "#The beauty of machine learning is that it can handle all of these\n",
    "#features at the same time. If there is different information present\n",
    "#in each feature, it should improve the classifier's ability to\n",
    "#distinguish the types of audio. Note that this often requires more\n",
    "#advanced techniques such as regularization, which we'll cover in\n",
    "#the next chapter.\n",
    "\n",
    "#For the final exercise in the chapter, we've loaded many of the\n",
    "#features that you calculated before. Combine all of them into an\n",
    "#array that can be fed into the classifier, and see how it does.\n",
    "\n",
    "# Loop through each spectrogram\n",
    "#bandwidths = []\n",
    "#centroids = []\n",
    "\n",
    "#for spec in spectrograms:\n",
    "    # Calculate the mean spectral bandwidth\n",
    "#    this_mean_bandwidth = np.mean(lr.feature.spectral_bandwidth(S=spec))\n",
    "    # Calculate the mean spectral centroid\n",
    "#    this_mean_centroid = np.mean(lr.feature.spectral_centroid(S=spec))\n",
    "    # Collect the values\n",
    "#    bandwidths.append(this_mean_bandwidth)\n",
    "#    centroids.append(this_mean_centroid)\n",
    "\n",
    "# Create the X and y arrays\n",
    "#X = np.column_stack([means, stds, maxs, tempo_mean, tempo_max, tempo_std, bandwidths, centroids])\n",
    "#y = labels.reshape([-1, 1])\n",
    "\n",
    "# Fit the model and score on testing data\n",
    "#percent_score = cross_val_score(model, X, y, cv=5)\n",
    "#print(np.mean(percent_score))\n",
    "\n",
    "#################################################\n",
    "#<script.py> output:\n",
    "#    0.483333333333\n",
    "#################################################\n",
    "#You calculated many different features of the audio, and combined\n",
    "#each of them under the assumption that they provide independent \n",
    "#information that can be used in classification. You may have noticed \n",
    "#that the accuracy of your models varied a lot when using different\n",
    "#set of features. This chapter was focused on creating new \"features\" \n",
    "#from raw data and not obtaining the best accuracy. To improve the\n",
    "#accuracy, you want to find the right features that provide relevant \n",
    "#information and also build models on much larger data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}